# J.A.R.V.I.S. - Just An Adaptive Real-time Voice Interactive System

## ğŸ› ï¸ Introduzione
J.A.R.V.I.S. (Just An Adaptive Real-time Voice Interactive System) Ã¨ un sistema interattivo vocale adattivo in tempo reale basato su **Flask**, **Whisper AI**, e tecnologie di analisi emotiva. Il progetto Ã¨ stato sviluppato per offrire un'interazione vocale avanzata, con trascrizione dell'audio e possibilitÃ  di adattamento delle risposte in base al contesto e all'emozione dell'utente.

## ğŸš€ FunzionalitÃ 
- **Trascrizione Audio in Tempo Reale** âœ¨: Utilizza Whisper AI per convertire la voce in testo.
- **Analisi Emotiva** ğŸš€: Integra moduli di analisi del tono della voce e sentiment analysis per comprendere le emozioni.
- **Risposte Adattive** ğŸ’¡: Personalizza le risposte in base allo stato emotivo dell'utente.
- **Interfaccia API REST** ğŸ› : Supporto a richieste HTTP per l'elaborazione audio.

## ğŸ”§ Tecnologie Utilizzate
- **Python** (Flask per il server API)
- **Whisper AI** (per la trascrizione vocale)
- **OpenSMILE / Google Speech Emotion API** (per analisi emotiva)
- **NLP Libraries** (NLTK, VADER, TextBlob per sentiment analysis)
- **Unity + Oculus SDK** (per un'integrazione in AR, opzionale)

## ğŸ“¦ Installazione

### 1ï¸âƒ£ Clona il repository
```bash
git clone https://github.com/tuo-username/JARVIS.git
cd JARVIS
```

### 2ï¸âƒ£ Crea e attiva un ambiente virtuale
```bash
python -m venv venv
source venv/bin/activate  # Su Windows usa: venv\Scripts\activate
```

### 3ï¸âƒ£ Installa le dipendenze
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configura il file `.env`
Crea un file `.env` nella root del progetto e aggiungi la tua chiave API:
```plaintext
OPENAI_API_KEY=your_api_key_here
```

## â–¶ï¸ Avvio del Server
```bash
python app.py
```
Il server partirÃ  su `http://127.0.0.1:5000/`

## ğŸ“¡ API Endpoints
### **Trascrizione Audio**
**Endpoint:** `/process_audio`
- **Metodo:** `POST`
- **Parametri:**
  - `audio` (file audio da trascrivere)
- **Risposta:**
```json
{
  "transcription": "Testo trascritto dall'audio"
}
```

## ğŸ› ï¸ Prossimi sviluppi
- Integrazione avanzata con AR per esperienze immersive
- Implementazione di un sistema di feedback vocale personalizzato
- Miglioramento del riconoscimento emotivo

## ğŸ¤ Contributi
Se vuoi contribuire al progetto, sentiti libero di aprire una **Pull Request** o segnalare problemi nella sezione **Issues** del repository.

## ğŸ“œ Licenza
Questo progetto Ã¨ distribuito sotto licenza **MIT**. Consulta il file `LICENSE` per maggiori dettagli.

---

### ğŸ”¥ Creato con passione per un'interazione uomo-macchina sempre piÃ¹ empatica e intelligente! ğŸš€

